{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec36385",
   "metadata": {},
   "source": [
    "#  Market forecasting for car prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a58bfd",
   "metadata": {},
   "source": [
    "Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3401e493",
   "metadata": {},
   "source": [
    "Let's start with imports: Pandas will help us handling DataFrames, and BeautifulSoup will help us with the parsing of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb915a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e847f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup_object_creation(url):\n",
    "    try:\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(url)\n",
    "        time.sleep(20)\n",
    "        driver.maximize_window()\n",
    "        time.sleep(4)\n",
    "        \n",
    "        feed_list = driver.find_element(By.CSS_SELECTOR, \"div.feed_list\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        car_ad_elements = feed_list.find_elements(By.CSS_SELECTOR, 'div.feeditem.table[data-v-3ecba55a=\"\"]')\n",
    "        \n",
    "        for ad_element in car_ad_elements:\n",
    "            try:\n",
    "                time.sleep(4)\n",
    "                ad_element.click()\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        html_content = driver.page_source\n",
    "        \n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        return soup\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1ffdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_columns = ['car_title', 'sub_model', 'year_of_manufactoring', 'num_of_owners', 'car_engine_size', 'price']\n",
    "# 'num_of_kilometers', 'engine_type', 'gear_box', 'car_color', 'test_valid_until', 'current_ownership','former_ownership', 'suits_for_disabled', 'rate_of_pollution', 'region'\n",
    "df = pd.DataFrame(columns=ad_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072c7d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(soup, df):\n",
    "    # Defining the raw strings for the tags' names\n",
    "    item_id_raw = 'feed_item_{}'\n",
    "    car_title_raw = 'feed_item_{}_title'\n",
    "    data_year_raw = 'data_year_{}'\n",
    "    num_of_owners_raw = 'data_hand_{}'\n",
    "    car_engine_size_raw = 'data_engine_size_{}'\n",
    "    price_raw = 'feed_item_{}_price'\n",
    "    \n",
    "    # Iterating over 36 adverts that appear in the page\n",
    "    for i in range(36):\n",
    "        temp_dict_to_append = {}\n",
    "\n",
    "        current_id = item_id_raw.format(i)\n",
    "        current_title_id = car_title_raw.format(i)\n",
    "        current_year_id = data_year_raw.format(i)\n",
    "        current_num_of_owners=num_of_owners_raw.format(i)\n",
    "        current_car_engine_size = car_engine_size_raw.format(i)\n",
    "        current_price = price_raw.format(i)\n",
    "                \n",
    "        # Updating the dictionary\n",
    "        try:\n",
    "            temp_dict_to_append['car_title'] = soup.find('span', {'id': current_title_id}).find('span', class_='title').get_text().strip()\n",
    "        except:\n",
    "            temp_dict_to_append['car_title'] = None\n",
    "        try:\n",
    "            temp_dict_to_append['sub_model'] = soup.find('div', {'id': current_id}).find('span', class_='subtitle').get_text()\n",
    "        except:\n",
    "            temp_dict_to_append['sub_model'] = None\n",
    "        try:\n",
    "            temp_dict_to_append['year_of_manufactoring'] = soup.find('span', {'id': current_year_id}).get_text()\n",
    "        except:\n",
    "            temp_dict_to_append['year_of_manufactoring'] = None\n",
    "        try:\n",
    "            temp_dict_to_append['num_of_owners'] = soup.find('span', {'id': current_num_of_owners}).get_text()\n",
    "        except:\n",
    "            temp_dict_to_append['num_of_owners'] = None\n",
    "        try:\n",
    "            temp_dict_to_append['car_engine_size'] = soup.find('span', {'id': current_car_engine_size}).get_text()\n",
    "        except:\n",
    "            temp_dict_to_append['car_engine_size'] = None\n",
    "        try:\n",
    "            temp_dict_to_append['price'] = soup.find('div', {'id': current_price}).get_text().strip().split(' ')[0].replace(',', '')\n",
    "        except:\n",
    "            temp_dict_to_append['price'] = None\n",
    "        try:\n",
    "            temp_dict_to_append['air_pollution_rate'] = soup.find('div', {'id': current_id}).find('div', class_='level_color selected').get_text().strip()\n",
    "        except:\n",
    "            temp_dict_to_append['air_pollution_rate'] = None\n",
    "        \n",
    "        # Taking care of the dynamic fields and updating the dictionary accordingly\n",
    "        temp_details_wrapper = soup.find('div', {'id': current_id}).find('div', attrs={'data-v-27ef3d9f': True, 'data-v-212a6bed': True})\n",
    "        \n",
    "        try:\n",
    "            temp_dl_tags_array = temp_details_wrapper.find_all('dl')\n",
    "            for detail in temp_dl_tags_array:\n",
    "                dt_tag = detail.find('dt').get_text().strip()\n",
    "                dd_tag = detail.find('dd').find('span').get_text().strip()\n",
    "                temp_dict_to_append[dt_tag] = dd_tag\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        # For debugging purposes\n",
    "        print(temp_dict_to_append)\n",
    "        \n",
    "        # Converting the dictionary to an DataFrame so we can append it to the original one\n",
    "        dict_as_pd = pd.DataFrame(temp_dict_to_append, index=[0])\n",
    "        df = pd.concat([df, dict_as_pd], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97815c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling_yad_2(df):\n",
    "    base_url_to_adjust = 'https://www.yad2.co.il/vehicles/cars?priceOnly=1&page={}'\n",
    "    temp = 2\n",
    "    \n",
    "    while temp <= 220:\n",
    "        temp_url = base_url_to_adjust.format(temp)\n",
    "        soup = soup_object_creation(temp_url)\n",
    "        df = fetch_data(soup, df)\n",
    "        time.sleep(4)\n",
    "        print('Scraped page number {}'.format(temp))\n",
    "        temp+=1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7134d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = crawling_yad_2(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87106252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('concat_df.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
